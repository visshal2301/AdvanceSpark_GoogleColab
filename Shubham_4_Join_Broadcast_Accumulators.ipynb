{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML6BdDsITQldKkS+6AaEC5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visshal2301/AdvanceSpark_GoogleColab/blob/main/Shubham_4_Join_Broadcast_Accumulators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drHn1Ejxm297",
        "outputId": "41b0be42-e934-40ce-e7cd-9b0d84c92f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|val1|\n",
            "+---+----+\n",
            "|  1|   A|\n",
            "|  2|   B|\n",
            "|  3|   C|\n",
            "+---+----+\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [id#10L, val1#9]\n",
            "   +- BroadcastHashJoin [id#10L], [id#8L], Inner, BuildRight, false\n",
            "      :- Range (0, 1000000, step=1, splits=2)\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=160]\n",
            "         +- Filter isnotnull(id#8L)\n",
            "            +- Scan ExistingRDD[id#8L,val1#9]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#BroadCast\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"BroadcastJoinExample\").getOrCreate()\n",
        "\n",
        "# Small dataset (can be broadcasted)\n",
        "small_df = spark.createDataFrame(\n",
        "    [(1, \"A\"), (2, \"B\"), (3, \"C\")],\n",
        "    [\"id\", \"val1\"]\n",
        ")\n",
        "\n",
        "# Large dataset\n",
        "large_df = spark.range(0, 1000000).withColumnRenamed(\"id\", \"id\")\n",
        "\n",
        "# Force Broadcast Hash Join\n",
        "broadcast_join = large_df.join(small_df.hint(\"BROADCAST\"), \"id\", \"inner\")\n",
        "\n",
        "broadcast_join.show(5)\n",
        "broadcast_join.explain()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are absolutely right! The explain() output clearly shows that Spark applied a BroadcastHashJoin.\n",
        "\n",
        "Specifically, you can see BroadcastHashJoin listed in the physical plan, and below it, BroadcastExchange indicates that the small_df (the right side of the join, BuildRight) was broadcasted to all executor nodes. This confirms the broadcast strategy was successfully utilized as intended by the hint(\"BROADCAST\")."
      ],
      "metadata": {
        "id": "Pmu0E_odo1uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Default value: 10 MB (in most Spark versions).\n",
        "- can be configured to 8 gb . but it is very unlikely that process will happen\n",
        "\n",
        "- Meaning: If the size of a DataFrame/table is estimated to be less than this threshold, Spark will broadcast it to all worker nodes and perform a Broadcast Hash Join.\n",
        "- Effect: This avoids shuffling the larger dataset, making joins much faster for small lookup tables.\n"
      ],
      "metadata": {
        "id": "rBoeUtinrkWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KxfquLTnrtXz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#broadcast Hash Join\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BroadcastJoinExample\").getOrCreate()\n",
        "\n",
        "# Medium-sized dataset (too large to broadcast efficiently)\n",
        "medium_df = spark.range(0, 500000).withColumnRenamed(\"id\", \"id\")\n",
        "\n",
        "# Another large dataset\n",
        "large_df2 = spark.range(0, 1000000).withColumnRenamed(\"id\", \"id\")\n",
        "\n",
        "# Force Shuffle Hash Join\n",
        "shuffle_hash_join = medium_df.hint(\"SHUFFLE_HASH\").join(large_df2, \"id\", \"inner\")\n",
        "\n",
        "# The original intention might have been to show some rows and then explain the plan.\n",
        "# If you intended to save the DataFrame, you need to specify a format and a path, e.g.:\n",
        "# shuffle_hash_join.write.format(\"parquet\").mode(\"overwrite\").save(\"output_path.parquet\")\n",
        "\n",
        "# Showing the top 5 rows\n",
        "shuffle_hash_join.show(5)\n",
        "\n",
        "# Explaining the physical plan of the join\n",
        "shuffle_hash_join.explain()\n",
        "\n",
        "# To simulate a write without actually writing the data, call .explain() on the DataFrameWriter\n",
        "# This shows the plan for the write operation.\n",
        "# The DataFrameWriter object itself does not have an explain method.\n",
        "# The explain() on the DataFrame itself (as shown above) usually provides the relevant plan.\n",
        "# print(\"\\n--- Explaining the write operation (simulation only) ---\")\n",
        "# shuffle_hash_join.write.format(\"parquet\").mode(\"overwrite\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3qEDue8pA75",
        "outputId": "7050ed9b-abed-4660-ed23-e6fc5d8cd5e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|  id|\n",
            "+----+\n",
            "|  26|\n",
            "|  29|\n",
            "| 474|\n",
            "| 964|\n",
            "|1677|\n",
            "+----+\n",
            "only showing top 5 rows\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [id#19L]\n",
            "   +- ShuffledHashJoin [id#19L], [id#21L], Inner, BuildLeft\n",
            "      :- Exchange hashpartitioning(id#19L, 200), ENSURE_REQUIREMENTS, [plan_id=262]\n",
            "      :  +- Range (0, 500000, step=1, splits=2)\n",
            "      +- Exchange hashpartitioning(id#21L, 200), ENSURE_REQUIREMENTS, [plan_id=263]\n",
            "         +- Range (0, 1000000, step=1, splits=2)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of explain() confirms that a ShuffledHashJoin was applied, as you explicitly hinted for with medium_df.hint(\"SHUFFLE_HASH\").\n",
        "\n",
        "Key elements in the physical plan that confirm this are:\n",
        "\n",
        "ShuffledHashJoin: This directly indicates the join strategy used.\n",
        "Exchange hashpartitioning: You'll see this operation for both datasets (medium_df and large_df2). This signifies that both DataFrames were re-partitioned (shuffled) across the network based on their join keys (id#33L and id#35L). This shuffling is necessary for a shuffle hash join to ensure that all rows with the same join key are brought together on the same executor to perform the hash join locally."
      ],
      "metadata": {
        "id": "2ZtsRRpLplQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Both datasets are shuffled across the cluster by id.\n",
        "- In each partition, Spark builds a hash table from the smaller side (medium_df relative to large_df2).\n",
        "- The larger dataset probes the hash table for matches.\n",
        "- Broadcast is avoided because medium_df is too large to efficiently send to every executor.\n"
      ],
      "metadata": {
        "id": "5eI_o17zpyi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Broadcast Hash Join: Best when one dataset is very small (few MBs).\n",
        "- Shuffle Hash Join: Used when broadcast is infeasible but hashing is still efficient\n"
      ],
      "metadata": {
        "id": "oAH-p6GYq1N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ShuffleHashJoinExample\").getOrCreate()\n",
        "\n",
        "# Two medium-sized DataFrames (too large to broadcast efficiently)\n",
        "df1 = spark.range(0, 500000).withColumnRenamed(\"id\", \"id\")\n",
        "df2 = spark.range(250000, 750000).withColumnRenamed(\"id\", \"id\")\n",
        "\n",
        "# Force Shuffle Hash Join using a hint\n",
        "joined_df = df1.hint(\"SHUFFLE_HASH\").join(df2, \"id\", \"inner\")\n",
        "\n",
        "joined_df.show(5)\n",
        "shuffle_hash_join.explain()"
      ],
      "metadata": {
        "id": "ZjLnKTOAqw7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8703db95-eaa6-443d-fb5d-91bef5f6001e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|    id|\n",
            "+------+\n",
            "|250267|\n",
            "|250622|\n",
            "|250722|\n",
            "|250780|\n",
            "|250953|\n",
            "+------+\n",
            "only showing top 5 rows\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [id#19L]\n",
            "   +- ShuffledHashJoin [id#19L], [id#21L], Inner, BuildLeft\n",
            "      :- Exchange hashpartitioning(id#19L, 200), ENSURE_REQUIREMENTS, [plan_id=262]\n",
            "      :  +- Range (0, 500000, step=1, splits=2)\n",
            "      +- Exchange hashpartitioning(id#21L, 200), ENSURE_REQUIREMENTS, [plan_id=263]\n",
            "         +- Range (0, 1000000, step=1, splits=2)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This physical plan confirms that a ShuffledHashJoin was performed, as intended by the hint. Here's a breakdown:\n",
        "\n",
        "ShuffledHashJoin [id#19L], [id#21L], Inner, BuildLeft: This is the core operation. It means Spark is using a Hash Join strategy where data is first shuffled.\n",
        "\n",
        "[id#19L], [id#21L]: These are the join keys from the two DataFrames (df1 and df2 in your example).\n",
        "Inner: Specifies the type of join.\n",
        "BuildLeft: Indicates that Spark built a hash table using the left DataFrame (df1, the smaller one after shuffling) in each partition.\n",
        "Exchange hashpartitioning(id#19L, 200), ENSURE_REQUIREMENTS (for both datasets): This is the crucial part that signifies shuffling.\n",
        "\n",
        "Exchange hashpartitioning: Both DataFrames are re-partitioned across the cluster based on the hash of their id column. This ensures that rows with the same id from both DataFrames end up on the same executor to be joined locally.\n",
        "200: Refers to the default number of partitions Spark creates during shuffling.\n",
        "In essence, Spark moved data across the network (shuffled) to group matching keys together, and then performed a hash join within each partition."
      ],
      "metadata": {
        "id": "hfAxzW5sumSk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQh79ZyUulvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}